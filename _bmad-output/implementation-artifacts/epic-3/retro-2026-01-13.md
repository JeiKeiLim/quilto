# Epic 3 Retrospective - Query & Retrieval

**Date:** 2026-01-13
**Facilitator:** Bob (Scrum Master)
**Epic Status:** Complete (4/4 stories done)

---

## Team Participants

- Alice (Product Owner)
- Bob (Scrum Master) - Facilitator
- Charlie (Senior Dev)
- Dana (QA Engineer)
- Elena (Junior Dev)
- Jongkuk Lim (Project Lead)

---

## Epic Summary

**Epic 3: Query & Retrieval**

| Metric | Value |
|--------|-------|
| Stories Completed | 4/4 (100%) |
| Tests Written | ~174 new tests |
| New Agents | 2 (Planner, Retriever) |
| New Domain Modules | 1 (Running) |
| Code Review Cycles | 4 |
| Production Incidents | 0 |

### Stories Delivered

| Story | Deliverable | Tests Added | Review Issues Fixed |
|-------|-------------|-------------|---------------------|
| 3-1 | Router QUERY/BOTH extension | 26 | 5 |
| 3-2 | Planner Agent (16 new types) | 52 | 7 |
| 3-3 | Retriever Agent (vocabulary expansion) | 72 | 8 |
| 3-4 | Running Domain Module | 71 | 8 |

### FRs Covered

- FR-F4: Retrieve relevant context (Retriever)
- FR-F7: QUERY/BOTH classification (Router extension)
- FR-F8: Query decomposition (Planner)
- FR-F9: Fetch entries using storage (Retriever)
- FR-A3: Running subdomain

---

## Epic 2 Retrospective Action Item Follow-Through

| # | Action Item | Status | Evidence |
|---|-------------|--------|----------|
| 1 | Create manual_test.py script | ✅ Completed | Script exists and was used during Epic 3 |
| 2 | Add "Common Mistakes" to project-context.md | ✅ Completed | Section exists with 7 documented patterns |
| 3 | Add pre-review checklist to story template | ✅ Completed | All Epic 3 stories have checklist |
| 4 | Fix Story 2-3 status mismatch | ✅ Completed | Status aligned |

**Follow-Through Assessment:** 4/4 action items completed (100%). All showed tangible benefit during Epic 3.

---

## What Went Well

### Successes

1. **100% story completion** with zero production incidents
2. **Clean architecture** - Router → Planner → Retriever with clear responsibilities
3. **Retriever as pure retrieval** (no LLM calls) - deterministic and highly testable
4. **Strong test coverage** - ~174 new tests across 4 stories
5. **manual_test.py script proved valuable** for mid-development testing
6. **All Epic 2 action items completed** and showed benefit
7. **Code review process matured** - catching issues proactively by Story 3-4

### Breakthrough Moments

- **Story 3-3:** Retriever design as pure retrieval (no LLM) made it deterministic and easy to test
- **Story 3-4:** Comprehensive Korean vocabulary for Running domain (러닝, 템포런, 인터벌, etc.)
- **Story 3-2:** `expand_terms()` function for vocabulary expansion - reusable foundation

### Patterns That Worked

| Pattern | Story | Impact |
|---------|-------|--------|
| Pure retrieval without LLM | 3-3 | 72 tests, deterministic behavior |
| Vocabulary expansion function | 3-3 | Reusable for future retrieval |
| Korean vocabulary from authoritative sources | 3-4 | Accurate normalization |
| manual_test.py for validation | All | Caught issues during development |

---

## Challenges Identified

### Circular Import Constraint

**Problem:** `RetrieverOutput.entries` uses `list[Any]` instead of `list[Entry]` due to circular import between `agents.models` and `storage.repository`.

**Impact:** Type safety reduced, requires comments explaining constraint.

**Resolution:** Documented as design constraint. Consider `types` module refactor if issue spreads to more agents.

### manual_test.py Not Auto-Updated

**Problem:** When new agents/domains were added, manual_test.py wasn't automatically updated until explicitly requested.

**Impact:** Script could become stale and lose value.

**Resolution:** Add explicit task to story template: "Check if manual_test.py update needed"

### Agent Response Quality with Local LLMs

**Problem:** Response quality varies with local Ollama models (qwen2.5:3b/7b) due to model capacity.

**Impact:** Some agent responses lack nuance.

**Resolution:** Not blocking. Maintain dual LLM support (local + cloud) as design principle. Users can choose cloud for better quality when needed.

---

## Key Learnings

1. **Clean agent separation pays off** - Each agent with single responsibility is easier to implement and test
2. **Pure retrieval (no LLM) is highly testable** - Deterministic logic allows comprehensive test coverage
3. **Keep manual_test.py current** - Manual validation is valuable but only if script stays updated
4. **Concerns often reduce to existing patterns** - Verdict-last is prompt engineering, retry loops are LangGraph patterns
5. **Dual LLM support is a feature** - Local for privacy/cost, cloud for quality - let users choose

---

## Epic 4 Preparation

### Epic 4: Analysis & Response

| Story | Description | Key Pattern |
|-------|-------------|-------------|
| 4-1 | Implement Analyzer Agent | Verdict-last pattern |
| 4-2 | Implement Synthesizer Agent | Response generation |
| 4-3 | Implement Evaluator Agent | Retry loop (2 retries → partial + gaps) |
| 4-4 | Add fitness expertise and evaluation rules | Domain-specific rules |

### Dependencies Verified

- ✅ Retriever output (entries) ready for Analyzer
- ✅ Planner gap analysis patterns established
- ✅ Agent implementation patterns from Epic 3 apply

### Concerns Resolved

| Initial Concern | Resolution |
|-----------------|------------|
| Verdict-last pattern complexity | Prompt engineering + structured Pydantic output |
| Retry loop state management | LangGraph handles state tracking - that's why we chose it |

### Technical Readiness

- No blockers identified
- Patterns from Epic 2-3 apply directly
- LangGraph designed for retry loop scenarios

---

## Action Items

| # | Action Item | Owner | Priority | Deadline |
|---|-------------|-------|----------|----------|
| 1 | Add "Check if manual_test.py update needed" task to story template | Bob (SM) | HIGH | Before first Epic 4 story |
| 2 | Document dual LLM support as design principle in project-context.md | Charlie (Dev) | MEDIUM | Before Epic 4 |

---

## Technical Debt

| Item | Severity | Notes |
|------|----------|-------|
| Circular import in RetrieverOutput (list[Any]) | LOW | Documented constraint. Refactor if spreads to more agents. |
| Prompt quality for local LLMs | LOW | Not blocking. Dual LLM support means users can choose cloud. |

---

## Team Agreements

1. **Every story checks if manual_test.py needs updating** - Explicit task in story template
2. **Maintain dual LLM support (local + cloud)** - Design principle, not either/or decision
3. **Apply existing patterns to new challenges** - Verdict-last is prompting, retry loops are LangGraph

---

## Retrospective Outcome

| Item | Status |
|------|--------|
| Epic 3 Review | Complete |
| Previous Retro Follow-Through | 4/4 completed (100%) |
| Action Items | 2 captured |
| Technical Debt | 2 items (both LOW) |
| Team Agreements | 3 captured |
| Next Epic Ready | Yes - no blockers |

---

## Closing Notes

**Jongkuk Lim (Project Lead):** "Good follow-through on Epic 2 action items. manual_test.py was helpful during development. Let's keep it updated."

**Team Consensus:** Epic 3 delivered clean architecture with strong test coverage. Epic 4 patterns (verdict-last, retry loops) are not new complexity - they're applications of prompt engineering and LangGraph. Ready to proceed.

---

*Retrospective facilitated by Bob (Scrum Master)*
*Document generated: 2026-01-13*
