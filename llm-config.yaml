# Quilto LLM Configuration - SAMPLE CONFIG
# ==========================================
# This is a sample configuration for local development.
# Copy this file or use these values when implementing LLM-using agents.
#
# MINIMUM REQUIREMENT: qwen2.5:7b (or equivalent)
# Smaller models (e.g., 3b) are unreliable for structured JSON output
# and will fail to include required fields in agent responses.
#
# Qwen2.5 is recommended because it explicitly supports structured JSON output,
# which is required for Parser and other agents that return Pydantic models.

default_provider: "ollama"
# fallback_provider: "anthropic"  # Uncomment when ANTHROPIC_API_KEY is set

providers:
  ollama:
    api_base: "http://localhost:11434"
  # anthropic:
  #   api_key: "${ANTHROPIC_API_KEY}"

# Model tiers - matched to 16GB RAM constraint
# All tiers use 7b minimum - smaller models unreliable for structured output
tiers:
  low:
    ollama: "qwen2.5:7b"
    # anthropic: "claude-3-haiku-20240307"
  medium:
    ollama: "qwen2.5:7b"
    # anthropic: "claude-3-5-sonnet-20241022"
  high:
    ollama: "qwen2.5:7b"
    # anthropic: "claude-3-5-sonnet-20241022"

# Agent tier assignments
agents:
  router:
    tier: low
  parser:
    tier: medium
  planner:
    tier: medium
  retriever:
    tier: low
  analyzer:
    tier: high
  synthesizer:
    tier: high
  evaluator:
    tier: medium
  clarifier:
    tier: low
  observer:
    tier: medium
